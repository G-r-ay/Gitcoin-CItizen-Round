{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "api_key = 'api-key'\n",
    "\n",
    "url = \"https://api-optimistic.etherscan.io/api\"\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_last_info(address):\n",
    "\n",
    "    params = {\n",
    "        \"module\": \"account\",\n",
    "        \"action\": \"txlist\",\n",
    "        \"address\": address,\n",
    "        \"page\": 1,\n",
    "        \"offset\": 100,\n",
    "        \"startblock\": 0,\n",
    "        \"endblock\": 99999999,\n",
    "        \"sort\": \"asc\",\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params).json()\n",
    "    response = response['result']\n",
    "    first_date = response[0]['timeStamp']\n",
    "    last_date = response[-1]['timeStamp']\n",
    "\n",
    "    first_to = response[0]['to']\n",
    "    first_from = response[0]['from']\n",
    "\n",
    "    last_to = response[-1]['to']\n",
    "    last_from = response[-1]['from']\n",
    "\n",
    "    if first_to == address:\n",
    "        first_to = 'self'\n",
    "    if first_from == address:\n",
    "        first_from = 'self'\n",
    "    if last_to == address:\n",
    "        last_to = 'self'\n",
    "    if last_from == address:\n",
    "        last_from = 'self'\n",
    "\n",
    "    return [first_date, last_date, first_from, first_to, last_from, last_to]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transaction_history(address):\n",
    "\n",
    "    params = {\n",
    "        \"module\": \"account\",\n",
    "        \"action\": \"txlist\",\n",
    "        \"address\": address,\n",
    "        \"page\": 1,\n",
    "        \"offset\": 100,\n",
    "        \"startblock\": 0,\n",
    "        \"endblock\": 99999999,\n",
    "        \"sort\": \"asc\",\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params).json()\n",
    "    return response['result']\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_Erc20_transaction_history(address):\n",
    "\n",
    "    params = {\n",
    "        \"module\": \"account\",\n",
    "        \"action\": \"tokentx\",\n",
    "        \"address\": address,\n",
    "        \"page\": 1,\n",
    "        \"offset\": 100,\n",
    "        \"startblock\": 0,\n",
    "        \"endblock\": 99999999,\n",
    "        \"sort\": \"asc\",\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params).json()\n",
    "    return response['result']\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_wallet_age(history: list[dict]):\n",
    "    if len(history) > 0:\n",
    "        creation_time = int(history[0]['timeStamp'])\n",
    "        creation_date = datetime.datetime.fromtimestamp(creation_time).date()\n",
    "        current_date = datetime.date.today()\n",
    "        wallet_age = (current_date - creation_date).days\n",
    "        return wallet_age\n",
    "    else:\n",
    "        return 0\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def to_and_from(history: list[dict], address):\n",
    "    from_count = 0\n",
    "    to_count = 0\n",
    "    for transactions in history:\n",
    "        if transactions['from'] == address:\n",
    "            from_count += 1\n",
    "        else:\n",
    "            to_count += 1\n",
    "    return from_count, to_count\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def fetch(address, nested_list):\n",
    "\n",
    "    reg_hist = get_transaction_history(address)\n",
    "    trasacting_hist = first_last_info(address)\n",
    "    erc20_hist = get_Erc20_transaction_history(address)\n",
    "\n",
    "    txn_count = len(reg_hist)\n",
    "\n",
    "    reg_age = get_wallet_age(reg_hist)\n",
    "    erc_age = get_wallet_age(erc20_hist)\n",
    "\n",
    "    reg_to, reg_from = to_and_from(reg_hist, address)\n",
    "    erc_to, erc_from = to_and_from(erc20_hist, address)\n",
    "\n",
    "    row = [address, txn_count, reg_age, erc_age, reg_to,\n",
    "           reg_from, erc_to, erc_from] + trasacting_hist\n",
    "\n",
    "    nested_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = pd.read_csv(\n",
    "    'votes_features_citizen_0x984e29dCB4286c2D9cbAA2c238AfDd8A191Eefbc.csv')\n",
    "original = pd.read_csv('Gitcoin Citizens  Round #1_ Retroactive funding .csv')\n",
    "\n",
    "\n",
    "votes['block_timestamp'] = pd.to_datetime(\n",
    "    votes['block_timestamp'], format=\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "votes = votes[['block_timestamp', 'tx_hash', 'voter', 'project', 'amount_usd']]\n",
    "votes.rename(columns={'block_timestamp': 'utc_time', 'amount_usd': 'amountUSD',\n",
    "             'tx_hash': 'transaction', 'project': 'grantAddress'}, inplace=True)\n",
    "votes.sort_values(by=['utc_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "original['grantAddress'] = original['grantAddress'].str.lower()\n",
    "votes['grantAddress'] = votes['grantAddress'].str.lower()\n",
    "\n",
    "mapping_dict = dict(zip(original['grantAddress'], original['title']))\n",
    "\n",
    "votes['title'] = votes['grantAddress'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run queries\n",
    "# headers = ['voter','txn_count','Wallet_Age','Wallet_Age(Erc20)','to_count','from_count','erc_to','erc_from','first_date','last_date','first_from','first_to','last_from','last_to']\n",
    "# contents = []\n",
    "\n",
    "# count = 0\n",
    "# for i in votes['voter'].unique():\n",
    "#     print(count)\n",
    "#     fetch(i,contents)\n",
    "#     count+=1\n",
    "\n",
    "# data = pd.DataFrame(contents,columns=headers)\n",
    "# data.to_csv('queried_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "queried = pd.read_csv('queried_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_counts = votes['voter'].value_counts()\n",
    "Address_info_sybil = pd.DataFrame(\n",
    "    {'Address': address_counts.index, 'Count': address_counts.values})\n",
    "\n",
    "funding_counts = votes['voter'].value_counts()\n",
    "count_by_address_project = votes.groupby(\n",
    "    ['voter', 'grantAddress']).size().reset_index(name='count')\n",
    "no_grants_funded = count_by_address_project['voter'].value_counts()\n",
    "\n",
    "# create a new dataframe with the address counts as a column\n",
    "Address_info1 = pd.DataFrame(\n",
    "    {'voter': funding_counts.index, 'Funding_count': funding_counts.values})\n",
    "Address_info2 = pd.DataFrame(\n",
    "    {'voter': no_grants_funded.index, 'No_Citizens_Funded': no_grants_funded.values})\n",
    "Address_info = pd.merge(Address_info1, Address_info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_votes = pd.merge(Address_info, votes, how='left', on='voter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "citizen_points = ['voter', 'Funding_count', 'No_Citizens_Funded', 'utc_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_votes['address'] = filtered_votes['voter']\n",
    "\n",
    "filtered_votes['project_title_sorted'] = filtered_votes['title'].apply(\n",
    "    lambda x: '-'.join(sorted(x.lower().split())))\n",
    "\n",
    "# group the rows by the address value and apply aggregation functions to the columns\n",
    "df_result = filtered_votes.groupby('address').agg({'voter': 'first',\n",
    "                                                   'project_title_sorted': '_'.join}).reset_index()\n",
    "\n",
    "# sort the resulting DataFrame by the count of project titles in descending order\n",
    "df_result = df_result.sort_values(by='project_title_sorted', ascending=False)[\n",
    "    ['voter', 'project_title_sorted']]\n",
    "\n",
    "cut_filtered_citizens = filtered_votes[citizen_points].drop_duplicates(subset=[\n",
    "                                                                       'voter'])\n",
    "\n",
    "cultivate_data_citizen = pd.merge(\n",
    "    cut_filtered_citizens, df_result, on='voter', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultivate_data_citizen = cultivate_data_citizen.loc[(cultivate_data_citizen['No_Citizens_Funded'] <= 7) & (cultivate_data_citizen['Funding_count'] <= 7)]\\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultivate_data_citizen = pd.merge(cultivate_data_citizen, queried, on='voter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultivate_data_citizen.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultivate_data_citizen.sort_values(by='utc_time', inplace=True)\n",
    "cultivate_data_citizen['unix_timestamp'] = cultivate_data_citizen['utc_time'].apply(lambda x: int(x.timestamp()))\n",
    "cultivate_data_citizen.set_index(\"utc_time\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "columns_to_encode = ['project_title_sorted',\n",
    "                     'first_from', 'first_to', 'last_from', 'last_to']\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    cultivate_data_citizen[col] = le.fit_transform(cultivate_data_citizen[col])\n",
    "\n",
    "columns_to_encode = ['project_title_sorted',\n",
    "                     'first_from', 'first_to', 'last_from', 'last_to']\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    cultivate_data_citizen[col] = le.fit_transform(cultivate_data_citizen[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "m = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = m.fit_transform(np.array(cultivate_data_citizen[cultivate_data_citizen.columns[1:]]))\n",
    "\n",
    "# Add supporterwallet column to data\n",
    "voter = cultivate_data_citizen['voter'].values.reshape(-1, 1)\n",
    "data = np.hstack((voter, data))\n",
    "\n",
    "similarity_matrix = cosine_similarity(data[:, 1:])\n",
    "\n",
    "# Set threshold for grouping together similar rows\n",
    "threshold = 0.9999999\n",
    "\n",
    "# Initialize list to store similar rows\n",
    "similar_rows = []\n",
    "\n",
    "# Loop through similarity matrix and group together similar rows\n",
    "for i in range(len(similarity_matrix)):\n",
    "    similar_row_indices = np.where(similarity_matrix[i] >= threshold)[0]\n",
    "    if len(similar_row_indices) > 1:\n",
    "        similar_row_values = [tuple(cultivate_data_citizen.iloc[j])\n",
    "                              for j in similar_row_indices]\n",
    "        if similar_row_values not in similar_rows:\n",
    "            similar_rows.append(similar_row_values)\n",
    "\n",
    "\n",
    "# Print out the similar rows\n",
    "import json\n",
    "\n",
    "similar_rows_json = {}\n",
    "\n",
    "# Loop through similarity matrix and group together similar rows\n",
    "for i, row_group in enumerate(similar_rows):\n",
    "    cluster_group = []\n",
    "    for row in row_group:\n",
    "        cluster_group.append(row[0])\n",
    "        if row[0] not in address:\n",
    "            address.add(row[0])\n",
    "    similar_rows_json[f\"Cluster Group {i}\"] = cluster_group\n",
    "\n",
    "# Serialize the similar_rows_json to a JSON file\n",
    "with open('sybil_clusters.json', 'w') as file:\n",
    "    json.dump(similar_rows_json, file,indent=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/user/.cache/huggingface/datasets/Poupou___csv/Poupou--citizen-round-features-d56265baa6629651/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f86e1a8695645b183b44786b0f4feac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "path = 'Poupou/citizen-round-features'\n",
    "ds = load_dataset(path=path)\n",
    "df = ds['train'].to_pandas()\n",
    "flagged = df['address'].loc[df['flagged'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ = 0\n",
    "for i in flagged.unique():\n",
    "    if i in address:\n",
    "        in_ += 1\n",
    "\n",
    "in_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
